{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":168063,"sourceType":"datasetVersion","datasetId":57273}],"dockerImageVersionId":30042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport glob\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:55:58.758865Z","iopub.execute_input":"2024-03-17T09:55:58.759220Z","iopub.status.idle":"2024-03-17T09:55:58.765648Z","shell.execute_reply.started":"2024-03-17T09:55:58.759190Z","shell.execute_reply":"2024-03-17T09:55:58.764836Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Data loading and preprocessing\ngen_paths = [\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset1/real/*.*',\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset2/real/*.*',\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset3/real/*.*',\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset4/real1/*.*',\n    '../input/handwritten-signatures/sample_Signature/sample_Signature/genuine/*.*'\n]\n\nforg_paths = [\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset1/forge/*.*',\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset2/forge/*.*',\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset3/forge/*.*',\n    '../input/handwritten-signatures/Dataset_Signature_Final/Dataset/dataset4/forge/*.*',\n    '../input/handwritten-signatures/sample_Signature/sample_Signature/forged/*.*'\n]\n\n\nnum_gen_signatures = sum([len(glob.glob(path)) for path in gen_paths])\nnum_forg_signatures = sum([len(glob.glob(path)) for path in forg_paths])\n\nprint(\"Number of genuine signatures:\", num_gen_signatures)\nprint(\"Number of forged signatures:\", num_forg_signatures)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:55:59.051649Z","iopub.execute_input":"2024-03-17T09:55:59.051959Z","iopub.status.idle":"2024-03-17T09:55:59.084868Z","shell.execute_reply.started":"2024-03-17T09:55:59.051928Z","shell.execute_reply":"2024-03-17T09:55:59.083973Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Number of genuine signatures: 510\nNumber of forged signatures: 510\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = []\ntrain_labels = []\ntest_data = []\ntest_labels = []\n\nfor paths in [gen_paths, forg_paths]:\n    for idx, path in enumerate(paths):\n        images = glob.glob(path)\n        for i, image_path in enumerate(images):\n            image = cv2.imread(image_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, (224, 224))\n            if idx == 3:\n                test_data.append(image)\n                test_labels.append(0 if paths == gen_paths else 1)\n            else:\n                train_data.append(image)\n                train_labels.append(0 if paths == gen_paths else 1)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:00.474039Z","iopub.execute_input":"2024-03-17T09:56:00.474365Z","iopub.status.idle":"2024-03-17T09:56:10.647968Z","shell.execute_reply.started":"2024-03-17T09:56:00.474337Z","shell.execute_reply":"2024-03-17T09:56:10.647204Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train_data = np.array(train_data) / 255.0\ntrain_labels = np.array(train_labels)\ntest_data = np.array(test_data) / 255.0\ntest_labels = np.array(test_labels)\n\ntrain_data, train_labels = shuffle(train_data, train_labels)\ntest_data, test_labels = shuffle(test_data, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:10.649934Z","iopub.execute_input":"2024-03-17T09:56:10.650205Z","iopub.status.idle":"2024-03-17T09:56:11.425353Z","shell.execute_reply.started":"2024-03-17T09:56:10.650179Z","shell.execute_reply":"2024-03-17T09:56:11.424591Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\ntrain_datagen.fit(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:11.426663Z","iopub.execute_input":"2024-03-17T09:56:11.427040Z","iopub.status.idle":"2024-03-17T09:56:11.804624Z","shell.execute_reply.started":"2024-03-17T09:56:11.427001Z","shell.execute_reply":"2024-03-17T09:56:11.803896Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Base model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:11.806108Z","iopub.execute_input":"2024-03-17T09:56:11.806496Z","iopub.status.idle":"2024-03-17T09:56:13.732246Z","shell.execute_reply.started":"2024-03-17T09:56:11.806455Z","shell.execute_reply":"2024-03-17T09:56:13.731499Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Model definition\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:13.734574Z","iopub.execute_input":"2024-03-17T09:56:13.734857Z","iopub.status.idle":"2024-03-17T09:56:14.589705Z","shell.execute_reply.started":"2024-03-17T09:56:13.734829Z","shell.execute_reply":"2024-03-17T09:56:14.588997Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Fine-tuning setup\nbase_model.trainable = True\nfine_tune_at = 100\n\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:14.591524Z","iopub.execute_input":"2024-03-17T09:56:14.591895Z","iopub.status.idle":"2024-03-17T09:56:14.607245Z","shell.execute_reply.started":"2024-03-17T09:56:14.591856Z","shell.execute_reply":"2024-03-17T09:56:14.606381Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=Adam(lr=0.0001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:14.608475Z","iopub.execute_input":"2024-03-17T09:56:14.608743Z","iopub.status.idle":"2024-03-17T09:56:14.654127Z","shell.execute_reply.started":"2024-03-17T09:56:14.608716Z","shell.execute_reply":"2024-03-17T09:56:14.653400Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n_________________________________________________________________\nglobal_average_pooling2d_2 ( (None, 2048)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               1049088   \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 24,637,313\nTrainable params: 20,502,529\nNon-trainable params: 4,134,784\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:14.655026Z","iopub.execute_input":"2024-03-17T09:56:14.655287Z","iopub.status.idle":"2024-03-17T09:56:14.660455Z","shell.execute_reply.started":"2024-03-17T09:56:14.655260Z","shell.execute_reply":"2024-03-17T09:56:14.659497Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Define epochs\nepochs = 50\n\n# Model training\nhistory_fine_tuned = model.fit(train_datagen.flow(train_data, train_labels, batch_size=32),\n                               steps_per_epoch=len(train_data) / 32,\n                               epochs=epochs,\n                               validation_data=(test_data, test_labels),\n                               callbacks=[early_stopping, reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2024-03-17T09:56:23.181502Z","iopub.execute_input":"2024-03-17T09:56:23.181859Z","iopub.status.idle":"2024-03-17T10:00:29.678234Z","shell.execute_reply.started":"2024-03-17T09:56:23.181825Z","shell.execute_reply":"2024-03-17T10:00:29.677244Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Epoch 1/50\n27/26 [==============================] - 10s 378ms/step - loss: 0.7508 - accuracy: 0.5286 - val_loss: 0.6853 - val_accuracy: 0.5556\nEpoch 2/50\n27/26 [==============================] - 9s 333ms/step - loss: 0.6949 - accuracy: 0.5893 - val_loss: 0.6959 - val_accuracy: 0.5500\nEpoch 3/50\n27/26 [==============================] - 9s 329ms/step - loss: 0.6768 - accuracy: 0.5988 - val_loss: 0.6957 - val_accuracy: 0.5333\nEpoch 4/50\n27/26 [==============================] - 9s 334ms/step - loss: 0.6085 - accuracy: 0.6821 - val_loss: 0.6321 - val_accuracy: 0.6778\nEpoch 5/50\n27/26 [==============================] - 9s 345ms/step - loss: 0.6028 - accuracy: 0.6798 - val_loss: 0.6123 - val_accuracy: 0.6611\nEpoch 6/50\n27/26 [==============================] - 9s 337ms/step - loss: 0.6123 - accuracy: 0.6690 - val_loss: 0.7960 - val_accuracy: 0.6500\nEpoch 7/50\n27/26 [==============================] - 9s 334ms/step - loss: 0.6060 - accuracy: 0.6821 - val_loss: 0.7979 - val_accuracy: 0.6278\nEpoch 8/50\n27/26 [==============================] - 9s 332ms/step - loss: 0.5689 - accuracy: 0.6964 - val_loss: 0.6869 - val_accuracy: 0.7333\nEpoch 9/50\n27/26 [==============================] - 9s 340ms/step - loss: 0.4737 - accuracy: 0.7690 - val_loss: 0.5233 - val_accuracy: 0.7778\nEpoch 10/50\n27/26 [==============================] - 9s 332ms/step - loss: 0.4419 - accuracy: 0.7929 - val_loss: 0.6184 - val_accuracy: 0.7667\nEpoch 11/50\n27/26 [==============================] - 9s 345ms/step - loss: 0.4529 - accuracy: 0.7750 - val_loss: 0.5948 - val_accuracy: 0.7889\nEpoch 12/50\n27/26 [==============================] - 9s 344ms/step - loss: 0.4449 - accuracy: 0.7869 - val_loss: 0.5734 - val_accuracy: 0.8056\nEpoch 13/50\n27/26 [==============================] - 9s 343ms/step - loss: 0.4075 - accuracy: 0.8036 - val_loss: 0.5027 - val_accuracy: 0.8278\nEpoch 14/50\n27/26 [==============================] - 9s 338ms/step - loss: 0.3883 - accuracy: 0.8310 - val_loss: 0.4742 - val_accuracy: 0.8333\nEpoch 15/50\n27/26 [==============================] - 9s 339ms/step - loss: 0.3895 - accuracy: 0.8143 - val_loss: 0.4626 - val_accuracy: 0.8444\nEpoch 16/50\n27/26 [==============================] - 9s 334ms/step - loss: 0.3592 - accuracy: 0.8381 - val_loss: 0.5103 - val_accuracy: 0.8333\nEpoch 17/50\n27/26 [==============================] - 9s 335ms/step - loss: 0.3659 - accuracy: 0.8333 - val_loss: 0.5054 - val_accuracy: 0.8278\nEpoch 18/50\n27/26 [==============================] - 9s 334ms/step - loss: 0.3688 - accuracy: 0.8417 - val_loss: 0.4892 - val_accuracy: 0.8333\nEpoch 19/50\n27/26 [==============================] - 9s 344ms/step - loss: 0.3495 - accuracy: 0.8464 - val_loss: 0.5371 - val_accuracy: 0.8111\nEpoch 20/50\n27/26 [==============================] - 9s 335ms/step - loss: 0.3285 - accuracy: 0.8524 - val_loss: 0.4753 - val_accuracy: 0.8500\nEpoch 21/50\n27/26 [==============================] - 9s 333ms/step - loss: 0.3297 - accuracy: 0.8417 - val_loss: 0.4873 - val_accuracy: 0.8667\nEpoch 22/50\n27/26 [==============================] - 9s 348ms/step - loss: 0.3468 - accuracy: 0.8429 - val_loss: 0.4861 - val_accuracy: 0.8556\nEpoch 23/50\n27/26 [==============================] - 9s 341ms/step - loss: 0.3254 - accuracy: 0.8595 - val_loss: 0.5478 - val_accuracy: 0.8444\nEpoch 24/50\n27/26 [==============================] - 9s 340ms/step - loss: 0.3091 - accuracy: 0.8690 - val_loss: 0.5132 - val_accuracy: 0.8333\nEpoch 25/50\n27/26 [==============================] - 9s 339ms/step - loss: 0.3059 - accuracy: 0.8667 - val_loss: 0.5189 - val_accuracy: 0.8500\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate model on test data\ntest_loss, test_accuracy = model.evaluate(test_data, test_labels)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:00:29.680319Z","iopub.execute_input":"2024-03-17T10:00:29.680754Z","iopub.status.idle":"2024-03-17T10:00:30.396301Z","shell.execute_reply.started":"2024-03-17T10:00:29.680708Z","shell.execute_reply":"2024-03-17T10:00:30.395357Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"6/6 [==============================] - 0s 73ms/step - loss: 0.4626 - accuracy: 0.8444\nTest Loss: 0.4625511169433594\nTest Accuracy: 0.8444444537162781\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\nmodel.save('Signature_Detection_Model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:01:26.734869Z","iopub.execute_input":"2024-03-17T10:01:26.735240Z","iopub.status.idle":"2024-03-17T10:01:27.457295Z","shell.execute_reply.started":"2024-03-17T10:01:26.735209Z","shell.execute_reply":"2024-03-17T10:01:27.456277Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom tensorflow.keras.models import load_model\n\n# Load the trained model\nmodel = load_model('Signature_Detection_Model.h5')\n\n# Define function to preprocess input image\ndef preprocess_image(image):\n    # Resize image to 224x224 (input size for ResNet model)\n    image = cv2.resize(image, (224, 224))\n    # Convert image to RGB (if it's in BGR)\n    if image.shape[2] == 3 and image.shape[0] != 3:\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    # Normalize pixel values to be between 0 and 1\n    image = image / 255.0\n    # Expand dimensions to match the input shape expected by the model\n    image = np.expand_dims(image, axis=0)\n    return image\n\n# Define function to predict signature authenticity\ndef predict_signature(image):\n    # Preprocess the input image\n    processed_image = preprocess_image(image)\n    # Make prediction\n    prediction = model.predict(processed_image)\n    # Convert prediction to class label (0: genuine, 1: forged)\n    label = \"Genuine\" if prediction[0][0] < 0.5 else \"Forged\"\n    return label, prediction[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:02:34.836873Z","iopub.execute_input":"2024-03-17T10:02:34.837266Z","iopub.status.idle":"2024-03-17T10:02:37.328754Z","shell.execute_reply.started":"2024-03-17T10:02:34.837230Z","shell.execute_reply":"2024-03-17T10:02:37.328015Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Test the model on real-time images\n# Example:\nimage_path = '/kaggle/input/handwritten-signatures/sample_Signature/sample_Signature/genuine/NFI-00204002.png'\nimage = cv2.imread(image_path)\nresult_label, result_confidence = predict_signature(image)\nprint(\"Predicted Label:\", result_label)\nprint(\"Confidence:\", result_confidence)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:03:05.882269Z","iopub.execute_input":"2024-03-17T10:03:05.882615Z","iopub.status.idle":"2024-03-17T10:03:05.943471Z","shell.execute_reply.started":"2024-03-17T10:03:05.882585Z","shell.execute_reply":"2024-03-17T10:03:05.942703Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Predicted Label: Genuine\nConfidence: 0.28076544\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model on real-time images\n# Example:\nimage_path = '/kaggle/input/handwritten-signatures/sample_Signature/sample_Signature/forged/NFI-00101029.PNG'\nimage = cv2.imread(image_path)\nresult_label, result_confidence = predict_signature(image)\nprint(\"Predicted Label:\", result_label)\nprint(\"Confidence:\", result_confidence)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T10:02:52.624595Z","iopub.execute_input":"2024-03-17T10:02:52.624922Z","iopub.status.idle":"2024-03-17T10:02:52.689761Z","shell.execute_reply.started":"2024-03-17T10:02:52.624894Z","shell.execute_reply":"2024-03-17T10:02:52.688957Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Predicted Label: Forged\nConfidence: 0.65542483\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}